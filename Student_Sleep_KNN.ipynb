{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn import preprocessing, neighbors, svm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "import pandas as pd\n",
    "from statistics import mean \n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('College_Sleep_Study.csv')\n",
    "#remove outliers\n",
    "df.replace('?', -99999, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Gender  ClassYear  LarkOwl  NumEarlyClass  EarlyClass   GPA  \\\n",
      "0         0          4  Neither              0           0  3.60   \n",
      "1         0          4  Neither              2           1  3.24   \n",
      "2         0          4      Owl              0           0  2.97   \n",
      "3         0          1     Lark              5           1  3.76   \n",
      "4         0          4      Owl              0           0  3.20   \n",
      "5         1          4  Neither              0           0  3.50   \n",
      "6         1          2     Lark              2           1  3.35   \n",
      "7         0          2     Lark              0           0  3.00   \n",
      "8         0          1  Neither              2           1  4.00   \n",
      "9         0          4  Neither              2           1  2.90   \n",
      "10        1          2  Neither              1           1  3.70   \n",
      "11        1          2  Neither              0           0  3.00   \n",
      "12        0          1  Neither              4           1  3.30   \n",
      "13        1          3  Neither              2           1  3.30   \n",
      "14        0          3  Neither              5           1  3.50   \n",
      "15        0          3     Lark              0           0  3.40   \n",
      "16        0          2  Neither              2           1  2.80   \n",
      "17        1          2     Lark              5           1  3.00   \n",
      "18        1          2  Neither              3           1  2.80   \n",
      "19        1          3      Owl              3           1  2.80   \n",
      "20        0          3  Neither              2           1  3.05   \n",
      "21        0          3  Neither              0           0  3.30   \n",
      "22        0          3  Neither              2           1  2.90   \n",
      "23        0          1  Neither              0           0  3.00   \n",
      "24        0          2  Neither              2           1  3.20   \n",
      "25        1          2      Owl              0           0  3.07   \n",
      "26        1          2      Owl              4           1  3.00   \n",
      "27        0          4  Neither              2           1  2.90   \n",
      "28        0          4  Neither              2           1  3.40   \n",
      "29        0          4  Neither              2           1  3.00   \n",
      "..      ...        ...      ...            ...         ...   ...   \n",
      "223       1          2      Owl              2           1  2.40   \n",
      "224       0          1  Neither              2           1  3.20   \n",
      "225       1          3      Owl              0           0  3.00   \n",
      "226       1          4  Neither              2           1  3.35   \n",
      "227       1          2      Owl              0           0  2.80   \n",
      "228       0          3     Lark              0           0  3.25   \n",
      "229       0          2     Lark              0           0  3.60   \n",
      "230       1          2  Neither              1           1  2.80   \n",
      "231       0          2  Neither              3           1  3.50   \n",
      "232       0          1  Neither              4           1  3.50   \n",
      "233       0          2  Neither              0           0  3.40   \n",
      "234       0          2     Lark              0           0  3.30   \n",
      "235       0          3  Neither              0           0  3.40   \n",
      "236       1          1  Neither              3           1  2.80   \n",
      "237       1          3  Neither              0           0  3.72   \n",
      "238       1          1  Neither              2           1  3.40   \n",
      "239       0          2     Lark              2           1  3.30   \n",
      "240       1          2  Neither              0           0  2.70   \n",
      "241       1          2      Owl              3           1  3.40   \n",
      "242       1          2  Neither              0           0  3.15   \n",
      "243       0          1  Neither              0           0  3.50   \n",
      "244       0          1     Lark              0           0  2.50   \n",
      "245       0          1      Owl              2           1  3.25   \n",
      "246       1          3  Neither              0           0  3.15   \n",
      "247       0          3     Lark              2           1  3.34   \n",
      "248       1          3  Neither              0           0  3.35   \n",
      "249       0          1  Neither              2           1  3.00   \n",
      "250       0          3  Neither              2           1  3.50   \n",
      "251       1          2  Neither              2           1  2.60   \n",
      "252       1          2  Neither              5           1  2.50   \n",
      "\n",
      "     ClassesMissed  CognitionZscore  PoorSleepQuality  StressScore  ...  \\\n",
      "0                0            -0.26                 4            8  ...   \n",
      "1                0             1.39                 6            3  ...   \n",
      "2               12             0.38                18            9  ...   \n",
      "3                0             1.39                 9            6  ...   \n",
      "4                4             1.22                 9           14  ...   \n",
      "5                0            -0.04                 6           28  ...   \n",
      "6                2             0.41                 2            1  ...   \n",
      "7                0            -0.59                10            3  ...   \n",
      "8                0             1.03                 5           20  ...   \n",
      "9                0             0.72                 2           31  ...   \n",
      "10               0             0.06                11           13  ...   \n",
      "11               0            -0.47                 8           11  ...   \n",
      "12               0            -0.14                 3           18  ...   \n",
      "13               6             0.04                 7            2  ...   \n",
      "14               1            -0.40                 4            3  ...   \n",
      "15               0             0.40                 4           11  ...   \n",
      "16               5            -0.80                 8           21  ...   \n",
      "17               0            -1.18                 8           20  ...   \n",
      "18               0            -0.40                 3            1  ...   \n",
      "19              20            -0.57                15           10  ...   \n",
      "20               4            -0.11                15           20  ...   \n",
      "21               1            -0.58                 5           12  ...   \n",
      "22               1            -0.05                 4           10  ...   \n",
      "23               5            -0.31                 6            6  ...   \n",
      "24               0            -0.33                 3            8  ...   \n",
      "25              20            -0.62                 9           16  ...   \n",
      "26              10             0.16                 5           14  ...   \n",
      "27               0            -0.04                 8           26  ...   \n",
      "28               3             0.78                 9            9  ...   \n",
      "29               2            -0.86                 6           14  ...   \n",
      "..             ...              ...               ...          ...  ...   \n",
      "223              3             0.11                13            0  ...   \n",
      "224              2             0.27                 8            2  ...   \n",
      "225              5            -0.49                 7            1  ...   \n",
      "226              2            -0.60                 7           16  ...   \n",
      "227              4             0.09                 8           13  ...   \n",
      "228              1            -0.37                 6           16  ...   \n",
      "229              0             0.12                 4            5  ...   \n",
      "230              6            -0.14                 2           11  ...   \n",
      "231              0            -0.72                 6            8  ...   \n",
      "232              0            -0.54                 3            5  ...   \n",
      "233              0            -1.11                 4            7  ...   \n",
      "234              6            -0.09                15           16  ...   \n",
      "235              0             0.02                 7           12  ...   \n",
      "236              1            -0.34                 4            0  ...   \n",
      "237              2            -0.01                 3            9  ...   \n",
      "238              0             0.39                10            8  ...   \n",
      "239              3            -0.38                 4           11  ...   \n",
      "240              0            -0.45                 5            3  ...   \n",
      "241              0            -0.14                 4            3  ...   \n",
      "242              2            -0.43                 5            3  ...   \n",
      "243              0            -1.05                10           10  ...   \n",
      "244              8            -1.13                10            4  ...   \n",
      "245              0            -0.38                 2            8  ...   \n",
      "246             10             0.59                 3            1  ...   \n",
      "247              0             0.91                 2            6  ...   \n",
      "248              7             0.87                11           15  ...   \n",
      "249              1            -0.32                 9            6  ...   \n",
      "250              1             1.30                 2            1  ...   \n",
      "251              0            -0.29                 5            3  ...   \n",
      "252              3            -1.00                 3            2  ...   \n",
      "\n",
      "    AlcoholUse  Drinks WeekdayBed  WeekdayRise  WeekdaySleep  WeekendBed  \\\n",
      "0     Moderate      10      25.75         8.70          7.70       25.75   \n",
      "1     Moderate       6      25.70         8.20          6.80       26.00   \n",
      "2        Light       3      27.44         6.55          3.00       28.00   \n",
      "3        Light       2      23.50         7.17          6.77       27.00   \n",
      "4     Moderate       4      25.90         8.67          6.09       23.75   \n",
      "5      Abstain       0      23.80         8.95          9.05       26.00   \n",
      "6     Moderate       6      25.35         8.48          7.73       25.63   \n",
      "7        Light       3      23.90         9.07          9.02       25.13   \n",
      "8        Light       3      24.40         8.75          8.25       24.00   \n",
      "9     Moderate       6      26.20         8.00          6.60       25.38   \n",
      "10    Moderate      10      25.00         8.53          8.23       25.25   \n",
      "11    Moderate      10      25.30         9.80          8.40       26.50   \n",
      "12    Moderate       4      25.92         7.97          6.34       26.29   \n",
      "13       Light       5      25.60         8.73          7.03       27.25   \n",
      "14     Abstain       0      22.90         6.90          8.40       22.25   \n",
      "15       Light       2      24.00         8.77          8.67       25.25   \n",
      "16    Moderate       4      22.90         6.85          8.25       23.75   \n",
      "17       Heavy      12      24.00         7.90          8.50       25.50   \n",
      "18    Moderate      10      25.77         9.52          8.55       25.25   \n",
      "19    Moderate       7      25.25         8.12          7.20       25.67   \n",
      "20       Light       1      24.50         7.80          7.40       25.50   \n",
      "21       Light       2      25.00         9.65          8.45       26.00   \n",
      "22    Moderate       7      24.63         9.04          9.74       25.75   \n",
      "23       Light       3      24.60         9.20          9.30       23.75   \n",
      "24     Abstain       0      24.60         8.25          7.65       25.50   \n",
      "25     Abstain       0      24.70        11.02         10.32       27.50   \n",
      "26    Moderate       8      24.40         7.95          8.45       24.00   \n",
      "27    Moderate       5      24.40         8.60          8.40       25.50   \n",
      "28       Light       3      23.90         7.80          8.00       25.25   \n",
      "29    Moderate       5      25.00         8.60          8.10       25.50   \n",
      "..         ...     ...        ...          ...           ...         ...   \n",
      "223      Light       1      26.10         9.62          7.82       26.75   \n",
      "224      Light       3      25.36        10.03          8.29       28.25   \n",
      "225      Heavy      15      29.10        12.02          7.02       30.25   \n",
      "226      Heavy      18      25.40         7.83          6.73       25.50   \n",
      "227   Moderate      10      25.90        10.20          8.20       26.00   \n",
      "228      Light       3      23.20         9.30         10.90       23.50   \n",
      "229      Light       2      22.30         8.20          9.90       24.50   \n",
      "230      Light      24      24.40         7.20          7.40       26.00   \n",
      "231      Light       2      26.30         7.35          5.35       26.00   \n",
      "232   Moderate       3      25.15         8.00          7.20       25.88   \n",
      "233      Light       4      24.80         9.25          9.25       24.75   \n",
      "234   Moderate       5      24.60         7.80          8.20       26.50   \n",
      "235      Heavy      10      24.80         7.80          7.60       26.00   \n",
      "236   Moderate       7      25.50         8.87          7.57       25.00   \n",
      "237      Light       3      24.90         8.47          7.77       25.00   \n",
      "238   Moderate       8      23.70         7.65          8.15       22.00   \n",
      "239   Moderate       6      24.15         8.58          8.43       25.50   \n",
      "240      Light       7      24.20        10.40         10.20       24.00   \n",
      "241    Abstain       0      24.90         9.20          8.70       24.88   \n",
      "242   Moderate      12      25.20        10.40          9.60       26.50   \n",
      "243   Moderate       6      24.20         8.27          7.67       26.25   \n",
      "244   Moderate       5      25.70         8.20          6.60       23.50   \n",
      "245   Moderate       7      25.35         9.40          8.55       25.25   \n",
      "246      Light       5      25.35         9.73          8.38       25.88   \n",
      "247    Abstain       0      24.00         7.45          7.55       24.00   \n",
      "248      Light       3      26.75         9.42          6.77       24.50   \n",
      "249      Light       5      23.60         8.63          9.03       24.50   \n",
      "250   Moderate       5      24.45         8.25          7.80       25.00   \n",
      "251   Moderate       7      24.38         9.20          8.97       26.00   \n",
      "252   Moderate      13      23.35         7.75          8.40       25.00   \n",
      "\n",
      "     WeekendRise  WeekendSleep  AverageSleep  AllNighter  \n",
      "0           9.50          5.88          7.18           0  \n",
      "1          10.00          7.25          6.93           0  \n",
      "2          12.59         10.09          5.02           0  \n",
      "3           8.00          7.25          6.90           0  \n",
      "4           9.50          7.00          6.35           0  \n",
      "5          10.75          9.00          9.04           0  \n",
      "6          10.13          7.00          7.52           1  \n",
      "7           9.75          9.00          9.01           0  \n",
      "8           9.00          9.25          8.54           0  \n",
      "9          10.25          6.88          6.68           0  \n",
      "10         10.75          7.75          8.09           0  \n",
      "11         10.75          8.50          8.43           0  \n",
      "12         11.25          8.25          6.89           0  \n",
      "13         11.50          8.50          7.45           0  \n",
      "14          9.50         10.25          8.93           0  \n",
      "15         10.50          9.50          8.90           0  \n",
      "16          9.09          8.59          8.34           0  \n",
      "17         10.50          7.50          8.22           0  \n",
      "18         11.25          8.00          8.39           1  \n",
      "19         10.50          8.00          7.43           0  \n",
      "20          8.75          7.00          7.29           0  \n",
      "21         10.38          8.88          8.57           0  \n",
      "22         10.50          8.50          9.39           0  \n",
      "23         11.75         10.25          9.57           0  \n",
      "24         10.38          8.88          8.00           0  \n",
      "25         12.25          8.75          9.87           0  \n",
      "26         11.75          9.50          8.75           0  \n",
      "27         11.00          9.00          8.57           0  \n",
      "28         10.00          7.00          7.71           0  \n",
      "29          8.50          5.75          7.43           0  \n",
      "..           ...           ...           ...         ...  \n",
      "223        11.75          8.25          7.94           0  \n",
      "224        12.96          9.67          8.68           1  \n",
      "225        15.00          8.50          7.44           1  \n",
      "226        10.75          8.50          7.24           0  \n",
      "227        10.00          8.25          8.21           1  \n",
      "228         8.00          6.50          9.64           0  \n",
      "229         8.00          7.50          9.21           0  \n",
      "230        10.50          7.00          7.29           0  \n",
      "231         9.13          6.38          5.64           0  \n",
      "232        10.13          7.38          7.25           1  \n",
      "233         9.75          7.00          8.61           0  \n",
      "234         9.00          4.00          7.00           0  \n",
      "235         9.50          6.00          7.14           0  \n",
      "236        11.50         10.00          8.26           0  \n",
      "237        10.00          8.50          7.98           0  \n",
      "238         5.25          6.75          7.75           0  \n",
      "239         9.34          7.84          8.26           0  \n",
      "240         9.50          9.50         10.00           0  \n",
      "241        10.75          8.88          8.75           0  \n",
      "242        10.50          7.00          8.86           0  \n",
      "243        10.92          9.67          8.24           0  \n",
      "244         6.00          6.25          6.50           1  \n",
      "245        11.00          8.50          8.54           0  \n",
      "246        10.25          8.38          8.38           0  \n",
      "247         8.00          7.75          7.61           0  \n",
      "248        10.50          9.50          7.55           1  \n",
      "249        10.00          9.50          9.17           0  \n",
      "250         9.75          8.75          8.07           0  \n",
      "251         9.88          7.50          8.55           0  \n",
      "252        10.88          9.88          8.82           0  \n",
      "\n",
      "[253 rows x 22 columns]\n"
     ]
    }
   ],
   "source": [
    "#drop categorical features that already have a numeric represenation\n",
    "df = df.drop(['DepressionStatus', 'AnxietyStatus'],1)\n",
    "#dop correlated features\n",
    "df = df.drop(['DepressionScore','AnxietyScore','DASScore'],1)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'cor' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-16-8b1d279949d1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#Correlation with output variable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mcor_target\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mabs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcor\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"GPA\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;31m#select scores\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mrelevant_features\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcor_target\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcor_target\u001b[0m\u001b[1;33m>\u001b[0m\u001b[1;36m0.09\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mrelevant_features\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'cor' is not defined"
     ]
    }
   ],
   "source": [
    "#Correlation with output variable\n",
    "cor_target = abs(cor[\"GPA\"])\n",
    "#select scores\n",
    "relevant_features = cor_target[cor_target>0.09]\n",
    "relevant_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "#only keep the features with correlations >= 0.1 with gpa\n",
    "newdf = df[['Gender','ClassYear','GPA','ClassesMissed','CognitionZscore','StressScore','WeekdayBed',     \n",
    "'WeekdayRise','WeekendBed','WeekendRise']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'newdf' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-fece8d85013d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m20\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m20\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mcor\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnewdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcorr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0msns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mheatmap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mannot\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcmap\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mReds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'newdf' is not defined"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1440x1440 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(20,20))\n",
    "cor = newdf.corr()\n",
    "sns.heatmap(cor, annot=True, cmap=plt.cm.Reds)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Chase\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:12: FutureWarning: set_value is deprecated and will be removed in a future release. Please use .at[] or .iat[] accessors instead\n",
      "  if sys.path[0] == '':\n",
      "C:\\Users\\Chase\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:10: FutureWarning: set_value is deprecated and will be removed in a future release. Please use .at[] or .iat[] accessors instead\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    }
   ],
   "source": [
    "#some algorithm require a categorical target feature while others accept a continuous value.\n",
    "#make 2 df one with a categorical feature and one with a continuous value.\n",
    "#loop through gpa to convert it to categorical\n",
    "for i in range(0,253):\n",
    "    if (newdf.at[i,'GPA'] >= 0.0) & (newdf.at[i,'GPA'] < 1.0):\n",
    "       newdf.set_value(i, \"GPA\", int(0))\n",
    "    elif (newdf.at[i,'GPA'] >= 1.0) & (newdf.at[i,'GPA'] <2.0):\n",
    "        newdf.set_value(i, \"GPA\", int(1))\n",
    "    elif (newdf.at[i,'GPA'] >= 2.0) & (newdf.at[i,'GPA'] <3.0):\n",
    "        newdf.set_value(i, \"GPA\", int(2))\n",
    "    else:\n",
    "        newdf.set_value(i, \"GPA\", int(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "#all fields must be numerical remove non numerical features and target feature\n",
    "#string type LarkOwl, AlcoholUse, DepressionStatus, AnxietyStatus, Stress\n",
    "x = np.array(newdf.drop(['GPA'],1))\n",
    "#df of only target feature\n",
    "y = np.array(newdf['GPA'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K Nearest Neighbors Training Average Accuracy:  0.7918627450980392\n",
      "Decision Tree Classifier Average Accuracy:  0.6856862745098039\n",
      "Support Vector Classifier Average Accuracy:  0.7926470588235294\n"
     ]
    }
   ],
   "source": [
    "''''Want to write a for loop here that will iterate through train_test_split, build models and get accuracy x times.\n",
    "Save the accuracies to arrays so we can get the average accuracy for each model'''\n",
    "clf1acc = []\n",
    "clf2acc = []\n",
    "clf3acc = []\n",
    "\n",
    "for i in range(0,100):\n",
    "    x_train, x_test, y_train, y_test = train_test_split(x,y,test_size = 0.4)\n",
    "    \n",
    "    clf1 = neighbors.KNeighborsClassifier(25)\n",
    "    clf1.fit(x_train, y_train)\n",
    "    accuracy = clf1.score(x_test, y_test)\n",
    "    clf1acc.append(accuracy)\n",
    "\n",
    "    clf2 = DecisionTreeClassifier()\n",
    "    clf2.fit(x_train, y_train)\n",
    "    accuracy = clf2.score(x_test, y_test)\n",
    "    clf2acc.append(accuracy)\n",
    "    \n",
    "    #Support Vector Classifier\n",
    "    clf3 = SVC(gamma='auto')\n",
    "    clf3.fit(x_train, y_train)\n",
    "    accuracy = clf3.score(x_test, y_test)\n",
    "    clf3acc.append(accuracy)\n",
    "    \n",
    "print('K Nearest Neighbors Training Average Accuracy: ', mean(clf1acc))\n",
    "print('Decision Tree Classifier Average Accuracy: ', mean(clf2acc))\n",
    "print('Support Vector Classifier Average Accuracy: ', mean(clf3acc))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x213c5161cc0>"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figuresize=(100,100)\n",
    "newdf['GPA'].plot.bar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "function calls for other algorithms!\n",
    "\n",
    "\n",
    "clf = svm.SVR()\n",
    "clf.fit(trainingData, trainingScores)\n",
    "print(\"SVR\")\n",
    "print(clf.predict(predictionData))\n",
    "\n",
    "clf = LogisticRegression()\n",
    "clf.fit(trainingData, trainingScores)\n",
    "print(\"LogisticRegression\")\n",
    "print(clf.predict(predictionData))\n",
    "\n",
    "\n",
    "clf = LinearDiscriminantAnalysis()\n",
    "clf.fit(trainingData, trainingScores)\n",
    "print(\"LinearDiscriminantAnalysis\")\n",
    "print(clf.predict(predictionData))\n",
    "\n",
    "clf = GaussianNB()\n",
    "clf.fit(trainingData, trainingScores)\n",
    "print(\"GaussianNB\")\n",
    "print(clf.predict(predictionData))\n",
    "\n",
    "clf = SVC()\n",
    "clf.fit(trainingData, trainingScores)\n",
    "print(\"SVC\")\n",
    "print(clf.predict(predictionData))'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
